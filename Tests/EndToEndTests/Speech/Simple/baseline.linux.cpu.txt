CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-1650 0 @ 3.20GHz
    Hardware threads: 12
    Total Memory: 32874316 kB
-------------------------------------------------------------------
=== Running /home/eldak/repo/cntk_github/CNTK/build/release/bin/cntk configFile=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Sep  6 2016 12:09:53
		Last modified date: Tue Sep  6 12:03:39 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-5.0
		Build Branch: eldak/deterministicCPU2
		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
		Built by eldak on atleneu04
		Build Path: /home/eldak/repo/cntk_github/CNTK
-------------------------------------------------------------------
Changed current directory to /home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
09/06/2016 12:25:43: -------------------------------------------------------------------
09/06/2016 12:25:43: Build info: 

09/06/2016 12:25:43: 		Built time: Sep  6 2016 12:09:53
09/06/2016 12:25:43: 		Last modified date: Tue Sep  6 12:03:39 2016
09/06/2016 12:25:43: 		Build type: release
09/06/2016 12:25:43: 		Build target: GPU
09/06/2016 12:25:43: 		With 1bit-SGD: no
09/06/2016 12:25:43: 		Math lib: mkl
09/06/2016 12:25:43: 		CUDA_PATH: /usr/local/cuda-7.5
09/06/2016 12:25:43: 		CUB_PATH: /usr/local/cub-1.4.1
09/06/2016 12:25:43: 		CUDNN_PATH: /usr/local/cudnn-5.0
09/06/2016 12:25:43: 		Build Branch: eldak/deterministicCPU2
09/06/2016 12:25:43: 		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
09/06/2016 12:25:43: 		Built by eldak on atleneu04
09/06/2016 12:25:43: 		Build Path: /home/eldak/repo/cntk_github/CNTK
09/06/2016 12:25:43: -------------------------------------------------------------------
09/06/2016 12:25:43: -------------------------------------------------------------------
09/06/2016 12:25:43: GPU info:

09/06/2016 12:25:43: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2045 MB
09/06/2016 12:25:43: -------------------------------------------------------------------

09/06/2016 12:25:43: Running on localhost at 2016/09/06 12:25:43
09/06/2016 12:25:43: Command line: 
/home/eldak/repo/cntk_github/CNTK/build/release/bin/cntk  configFile=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu  DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true


Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
09/06/2016 12:25:43: Commands: Simple_Demo Simple_Demo_Output
09/06/2016 12:25:43: Precision = "float"
09/06/2016 12:25:43: CNTKModelPath: /tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn
09/06/2016 12:25:43: CNTKCommandTrainInfo: Simple_Demo : 50
09/06/2016 12:25:43: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

09/06/2016 12:25:43: ##############################################################################
09/06/2016 12:25:43: #                                                                            #
09/06/2016 12:25:43: # Action "train"                                                             #
09/06/2016 12:25:43: #                                                                            #
09/06/2016 12:25:43: ##############################################################################

09/06/2016 12:25:43: CNTKCommandTrainBegin: Simple_Demo

09/06/2016 12:25:43: Creating virgin network.
SimpleNetworkBuilder Using CPU
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, init dims=[50 x 2], range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, init dims=[50 x 50], range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, init dims=[2 x 50], range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

09/06/2016 12:25:43: Created model with 25 nodes on CPU.

09/06/2016 12:25:43: Training criterion node(s):
09/06/2016 12:25:43: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

09/06/2016 12:25:43: Evaluation criterion node(s):
09/06/2016 12:25:43: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }


09/06/2016 12:25:43: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

09/06/2016 12:25:43: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:25:43: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:25:43: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
09/06/2016 12:25:43: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
09/06/2016 12:25:43: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
09/06/2016 12:25:43: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


09/06/2016 12:25:43: Precomputing --> 3 PreCompute nodes found.

09/06/2016 12:25:43: 	MeanOfFeatures = Mean()
09/06/2016 12:25:43: 	InvStdOfFeatures = InvStdDev()
09/06/2016 12:25:43: 	Prior = Mean()

09/06/2016 12:25:43: Precomputing --> Completed.


09/06/2016 12:25:43: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:43: Starting minibatch loop.
09/06/2016 12:25:43:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.76787934 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0336s; samplesPerSecond = 38089.6
09/06/2016 12:25:43:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.72901568 * 1280; EvalClassificationError = 0.50468750 * 1280; time = 0.0230s; samplesPerSecond = 55695.8
09/06/2016 12:25:43:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.69672222 * 1280; EvalClassificationError = 0.49765625 * 1280; time = 0.0230s; samplesPerSecond = 55674.0
09/06/2016 12:25:44:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69961834 * 1280; EvalClassificationError = 0.46250000 * 1280; time = 0.0264s; samplesPerSecond = 48488.5
09/06/2016 12:25:44:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69465542 * 1280; EvalClassificationError = 0.48515625 * 1280; time = 0.0237s; samplesPerSecond = 54118.0
09/06/2016 12:25:44:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.69459534 * 1280; EvalClassificationError = 0.41171875 * 1280; time = 0.0205s; samplesPerSecond = 62399.5
09/06/2016 12:25:44:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.65583725 * 1280; EvalClassificationError = 0.41796875 * 1280; time = 0.0239s; samplesPerSecond = 53453.6
09/06/2016 12:25:44: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.67760273 * 10000; EvalClassificationError = 0.43420000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.198705s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.1'

09/06/2016 12:25:44: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17325155 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0201s; samplesPerSecond = 63555.1
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20231584 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0234s; samplesPerSecond = 54757.0
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21851563 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0189s; samplesPerSecond = 67674.7
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19079666 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0236s; samplesPerSecond = 54205.1
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19158516 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0210s; samplesPerSecond = 60932.1
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18068714 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:44:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15414639 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:44: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.18580677 * 10000; EvalClassificationError = 0.07910000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.17911s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.2'

09/06/2016 12:25:44: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20254598 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0185s; samplesPerSecond = 69140.6
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18272650 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0210s; samplesPerSecond = 60972.7
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16485140 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53429.1
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17932067 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0217s; samplesPerSecond = 58991.6
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16228499 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0239s; samplesPerSecond = 53614.8
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17208128 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0211s; samplesPerSecond = 60712.4
09/06/2016 12:25:44:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15790358 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:44: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.17220903 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.174839s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.3'

09/06/2016 12:25:44: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15375857 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0192s; samplesPerSecond = 66600.8
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17569745 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0238s; samplesPerSecond = 53761.2
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16692860 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0239s; samplesPerSecond = 53458.1
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19348469 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0239s; samplesPerSecond = 53455.8
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16766157 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0210s; samplesPerSecond = 60894.4
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15068712 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:44:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15202265 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0215s; samplesPerSecond = 59476.8
09/06/2016 12:25:44: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16509668 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.175503s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.4'

09/06/2016 12:25:44: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15456637 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0203s; samplesPerSecond = 62914.7
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17114824 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0240s; samplesPerSecond = 53291.1
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15907705 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0236s; samplesPerSecond = 54313.2
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15822291 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0191s; samplesPerSecond = 67012.2
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17749352 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0237s; samplesPerSecond = 53897.0
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17140322 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:44:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17532101 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0210s; samplesPerSecond = 60914.7
09/06/2016 12:25:44: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16548099 * 10000; EvalClassificationError = 0.07580000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.180089s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.5'

09/06/2016 12:25:44: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17226899 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0183s; samplesPerSecond = 70129.3
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20439625 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0240s; samplesPerSecond = 53402.3
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15904801 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53420.1
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16455998 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0240s; samplesPerSecond = 53380.0
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18057728 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0210s; samplesPerSecond = 60969.8
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18234930 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:44:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18241692 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53440.2
09/06/2016 12:25:44: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.17461414 * 10000; EvalClassificationError = 0.07850000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.179785s
09/06/2016 12:25:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.6'

09/06/2016 12:25:44: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:44: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16126106 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0243s; samplesPerSecond = 52584.0
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17271674 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0189s; samplesPerSecond = 67803.8
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15257568 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0239s; samplesPerSecond = 53458.1
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13763065 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0195s; samplesPerSecond = 65530.1
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14629359 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0231s; samplesPerSecond = 55396.9
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17639127 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0239s; samplesPerSecond = 53608.1
09/06/2016 12:25:45:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17477665 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53382.3
09/06/2016 12:25:45: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16351710 * 10000; EvalClassificationError = 0.07730000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.180631s
09/06/2016 12:25:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.7'

09/06/2016 12:25:45: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:45: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16444900 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0183s; samplesPerSecond = 69972.1
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15843136 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0236s; samplesPerSecond = 54283.3
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16285515 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0188s; samplesPerSecond = 67915.3
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16373024 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0238s; samplesPerSecond = 53722.8
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16341076 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0210s; samplesPerSecond = 60923.4
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18030205 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53409.0
09/06/2016 12:25:45:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14125643 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0217s; samplesPerSecond = 59032.4
09/06/2016 12:25:45: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16304906 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.17416s
09/06/2016 12:25:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.8'

09/06/2016 12:25:45: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:45: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18143728 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0193s; samplesPerSecond = 66410.7
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18009384 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0240s; samplesPerSecond = 53375.6
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17607446 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0238s; samplesPerSecond = 53722.8
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17846565 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0238s; samplesPerSecond = 53844.9
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16922598 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0241s; samplesPerSecond = 53024.0
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15430174 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0167s; samplesPerSecond = 76701.8
09/06/2016 12:25:45:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15592928 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0220s; samplesPerSecond = 58218.9
09/06/2016 12:25:45: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.17140103 * 10000; EvalClassificationError = 0.07760000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.174754s
09/06/2016 12:25:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.9'

09/06/2016 12:25:45: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:45: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17334810 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0196s; samplesPerSecond = 65173.1
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15468954 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0190s; samplesPerSecond = 67251.6
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17982726 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0238s; samplesPerSecond = 53740.9
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16882715 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53395.6
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20348935 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0239s; samplesPerSecond = 53449.1
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16315107 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:45:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15775747 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0210s; samplesPerSecond = 60908.9
09/06/2016 12:25:45: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16880803 * 10000; EvalClassificationError = 0.07650000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.176057s
09/06/2016 12:25:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.10'

09/06/2016 12:25:45: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:45: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17671647 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0193s; samplesPerSecond = 66283.5
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16349745 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0238s; samplesPerSecond = 53749.9
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17284622 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0240s; samplesPerSecond = 53246.8
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16618757 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0237s; samplesPerSecond = 54008.4
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15637851 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0241s; samplesPerSecond = 53026.2
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15405188 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0187s; samplesPerSecond = 68405.3
09/06/2016 12:25:45:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16313667 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0240s; samplesPerSecond = 53260.1
09/06/2016 12:25:45: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.17006791 * 10000; EvalClassificationError = 0.07660000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.180797s
09/06/2016 12:25:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.11'

09/06/2016 12:25:45: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:45: Starting minibatch loop.
09/06/2016 12:25:45:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16747394 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0216s; samplesPerSecond = 59215.4
09/06/2016 12:25:45:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16926260 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0215s; samplesPerSecond = 59540.4
09/06/2016 12:25:45:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17724953 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:45:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16153216 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0238s; samplesPerSecond = 53840.3
09/06/2016 12:25:45:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15809488 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0279s; samplesPerSecond = 45801.0
09/06/2016 12:25:46:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16424341 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0360s; samplesPerSecond = 35586.2
09/06/2016 12:25:46:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14406061 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0268s; samplesPerSecond = 47732.7
09/06/2016 12:25:46: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16305184 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.213396s
09/06/2016 12:25:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.12'

09/06/2016 12:25:46: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:46: Starting minibatch loop.
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15032351 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0184s; samplesPerSecond = 69747.2
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17721360 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0333s; samplesPerSecond = 38417.7
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17323799 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0667s; samplesPerSecond = 19184.9
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15412526 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0240s; samplesPerSecond = 53417.9
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14742498 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0238s; samplesPerSecond = 53806.4
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17056408 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0271s; samplesPerSecond = 47147.2
09/06/2016 12:25:46:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15463085 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0180s; samplesPerSecond = 70937.7
09/06/2016 12:25:46: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16187958 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.2354s
09/06/2016 12:25:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.13'

09/06/2016 12:25:46: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:46: Starting minibatch loop.
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20428088 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0210s; samplesPerSecond = 61036.7
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20951297 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0239s; samplesPerSecond = 53484.9
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17470431 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20022736 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0240s; samplesPerSecond = 53440.2
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19115577 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53406.8
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16565638 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:46:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15861492 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0213s; samplesPerSecond = 60017.8
09/06/2016 12:25:46: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.18525466 * 10000; EvalClassificationError = 0.08160000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.185266s
09/06/2016 12:25:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.14'

09/06/2016 12:25:46: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:46: Starting minibatch loop.
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17293929 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0213s; samplesPerSecond = 60040.3
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14972337 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0240s; samplesPerSecond = 53395.6
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17388475 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0239s; samplesPerSecond = 53455.8
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16904759 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0213s; samplesPerSecond = 60077.0
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16738753 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0213s; samplesPerSecond = 60020.6
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16737280 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:46:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15916157 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0213s; samplesPerSecond = 60062.9
09/06/2016 12:25:46: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16554249 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.180317s
09/06/2016 12:25:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.15'

09/06/2016 12:25:46: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:46: Starting minibatch loop.
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17063624 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0205s; samplesPerSecond = 62573.3
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16444885 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53513.9
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17523324 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0239s; samplesPerSecond = 53453.6
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17308168 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18644814 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17276363 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0213s; samplesPerSecond = 60071.3
09/06/2016 12:25:46:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17704020 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0213s; samplesPerSecond = 60071.3
09/06/2016 12:25:46: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.17266423 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.182048s
09/06/2016 12:25:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.16'

09/06/2016 12:25:46: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:46: Starting minibatch loop.
09/06/2016 12:25:46:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15754168 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0178s; samplesPerSecond = 71825.4
09/06/2016 12:25:46:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16700337 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53371.1
09/06/2016 12:25:46:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18876448 * 1280; EvalClassificationError = 0.09453125 * 1280; time = 0.0239s; samplesPerSecond = 53484.9
09/06/2016 12:25:46:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16264739 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0239s; samplesPerSecond = 53543.0
09/06/2016 12:25:46:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15761566 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:47:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15861073 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0240s; samplesPerSecond = 53333.3
09/06/2016 12:25:47:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15868063 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0239s; samplesPerSecond = 53507.2
09/06/2016 12:25:47: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16474818 * 10000; EvalClassificationError = 0.07880000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.185623s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.17'

09/06/2016 12:25:47: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15372933 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0236s; samplesPerSecond = 54317.8
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16174213 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0187s; samplesPerSecond = 68618.0
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16805205 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15750542 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0213s; samplesPerSecond = 60071.3
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14848323 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0240s; samplesPerSecond = 53360.0
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15929031 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0239s; samplesPerSecond = 53605.8
09/06/2016 12:25:47:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15710373 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:47: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15840823 * 10000; EvalClassificationError = 0.07410000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.183379s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.18'

09/06/2016 12:25:47: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15729398 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0183s; samplesPerSecond = 69922.4
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15066613 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53411.2
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16931269 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15056415 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0213s; samplesPerSecond = 60051.6
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18283534 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0239s; samplesPerSecond = 53453.6
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16821423 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0239s; samplesPerSecond = 53518.4
09/06/2016 12:25:47:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17998962 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0239s; samplesPerSecond = 53471.5
09/06/2016 12:25:47: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16611069 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.177275s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.19'

09/06/2016 12:25:47: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16058820 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0178s; samplesPerSecond = 71978.9
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15364984 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0239s; samplesPerSecond = 53449.1
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15540874 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16862626 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0239s; samplesPerSecond = 53556.5
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15999022 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53413.5
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15753345 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53446.9
09/06/2016 12:25:47:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16873503 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53422.4
09/06/2016 12:25:47: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15916772 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.182015s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.20'

09/06/2016 12:25:47: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16457530 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0178s; samplesPerSecond = 71805.2
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14965638 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15823965 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0213s; samplesPerSecond = 60046.0
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14598193 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0240s; samplesPerSecond = 53417.9
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16491952 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0239s; samplesPerSecond = 53478.2
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17231426 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0239s; samplesPerSecond = 53543.0
09/06/2016 12:25:47:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16371145 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:47: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16036295 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.182963s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.21'

09/06/2016 12:25:47: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15611972 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0183s; samplesPerSecond = 70044.9
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13785256 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0213s; samplesPerSecond = 60108.0
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16535847 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53386.7
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16503291 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0239s; samplesPerSecond = 53478.2
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15546598 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0266s; samplesPerSecond = 48055.3
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15233245 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0239s; samplesPerSecond = 53473.7
09/06/2016 12:25:47:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19573660 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0213s; samplesPerSecond = 60026.3
09/06/2016 12:25:47: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261056 * 10000; EvalClassificationError = 0.07580000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.183362s
09/06/2016 12:25:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.22'

09/06/2016 12:25:47: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:47: Starting minibatch loop.
09/06/2016 12:25:47:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16898190 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0183s; samplesPerSecond = 69792.8
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17614683 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0240s; samplesPerSecond = 53393.4
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16341057 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0239s; samplesPerSecond = 53527.4
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16389289 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0215s; samplesPerSecond = 59651.4
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15507503 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0211s; samplesPerSecond = 60657.8
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16150293 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53400.1
09/06/2016 12:25:48:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15201712 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:48: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16328606 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.177244s
09/06/2016 12:25:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.23'

09/06/2016 12:25:48: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:48: Starting minibatch loop.
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18361137 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0178s; samplesPerSecond = 71756.9
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18937519 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0239s; samplesPerSecond = 53558.7
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15248947 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0239s; samplesPerSecond = 53458.1
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13488998 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0213s; samplesPerSecond = 60074.2
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18253484 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0213s; samplesPerSecond = 60000.9
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13559303 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0239s; samplesPerSecond = 53467.0
09/06/2016 12:25:48:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16215487 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0213s; samplesPerSecond = 60110.8
09/06/2016 12:25:48: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16349951 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.17676s
09/06/2016 12:25:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.24'

09/06/2016 12:25:48: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:48: Starting minibatch loop.
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14410825 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0204s; samplesPerSecond = 62631.5
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17700341 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0239s; samplesPerSecond = 53455.8
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14907324 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53409.0
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16086655 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0239s; samplesPerSecond = 53451.4
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17219219 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17564411 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0240s; samplesPerSecond = 53409.0
09/06/2016 12:25:48:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17609806 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:48: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16392158 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.188269s
09/06/2016 12:25:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.25'

09/06/2016 12:25:48: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:48: Starting minibatch loop.
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14948860 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0209s; samplesPerSecond = 61214.7
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18475274 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0213s; samplesPerSecond = 60060.1
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16298699 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0240s; samplesPerSecond = 53386.7
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14671760 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16988988 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0239s; samplesPerSecond = 53475.9
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12634602 * 1280; EvalClassificationError = 0.05156250 * 1280; time = 0.0240s; samplesPerSecond = 53357.8
09/06/2016 12:25:48:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16665192 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0213s; samplesPerSecond = 60082.6
09/06/2016 12:25:48: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15836489 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.182564s
09/06/2016 12:25:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.26'

09/06/2016 12:25:48: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:48: Starting minibatch loop.
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17073995 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0204s; samplesPerSecond = 62748.2
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17057620 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14733498 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0240s; samplesPerSecond = 53413.5
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15325294 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0213s; samplesPerSecond = 60040.3
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15593843 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0240s; samplesPerSecond = 53422.4
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15706940 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0239s; samplesPerSecond = 53471.5
09/06/2016 12:25:48:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17286139 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0213s; samplesPerSecond = 60034.7
09/06/2016 12:25:48: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16107898 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.18204s
09/06/2016 12:25:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.27'

09/06/2016 12:25:48: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:48: Starting minibatch loop.
09/06/2016 12:25:48:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16945839 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0178s; samplesPerSecond = 71752.9
09/06/2016 12:25:48:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18443935 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0239s; samplesPerSecond = 53590.1
09/06/2016 12:25:48:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16735666 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:48:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15123658 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0200s; samplesPerSecond = 63891.4
09/06/2016 12:25:48:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14052629 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53603.6
09/06/2016 12:25:49:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15429277 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53417.9
09/06/2016 12:25:49:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16686211 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53422.4
09/06/2016 12:25:49: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16312491 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.175406s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.28'

09/06/2016 12:25:49: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16114533 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0178s; samplesPerSecond = 71789.1
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13027835 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0240s; samplesPerSecond = 53404.5
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16984265 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0239s; samplesPerSecond = 53599.1
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15046000 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0240s; samplesPerSecond = 53393.4
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16504669 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0239s; samplesPerSecond = 53475.9
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14679303 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:49:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17150068 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:49: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16135596 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.182083s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.29'

09/06/2016 12:25:49: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16378827 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0178s; samplesPerSecond = 71809.3
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350196 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0239s; samplesPerSecond = 53473.7
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16200140 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0213s; samplesPerSecond = 60060.1
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17997212 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53429.1
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17179399 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0239s; samplesPerSecond = 53578.9
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16910982 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0240s; samplesPerSecond = 53440.2
09/06/2016 12:25:49:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17447052 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:49: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16685378 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.179371s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.30'

09/06/2016 12:25:49: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17310435 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0178s; samplesPerSecond = 71748.9
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17225746 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53404.5
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19278526 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0213s; samplesPerSecond = 60088.3
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14848056 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0240s; samplesPerSecond = 53273.4
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17797055 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0239s; samplesPerSecond = 53594.6
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14993353 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0239s; samplesPerSecond = 53578.9
09/06/2016 12:25:49:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15609417 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:49: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.16720474 * 10000; EvalClassificationError = 0.08070000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.182955s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.31'

09/06/2016 12:25:49: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16825123 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0183s; samplesPerSecond = 69979.8
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15172620 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53384.5
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14193788 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0213s; samplesPerSecond = 60082.6
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16006799 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0239s; samplesPerSecond = 53449.1
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15443039 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0239s; samplesPerSecond = 53583.4
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17014613 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:49:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15410852 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0240s; samplesPerSecond = 53411.2
09/06/2016 12:25:49: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15899670 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.177243s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.32'

09/06/2016 12:25:49: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16432738 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0218s; samplesPerSecond = 58823.5
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17564251 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0187s; samplesPerSecond = 68566.5
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15467417 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0213s; samplesPerSecond = 60079.8
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15989141 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0239s; samplesPerSecond = 53585.6
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14214611 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0240s; samplesPerSecond = 53409.0
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15155411 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0239s; samplesPerSecond = 53460.3
09/06/2016 12:25:49:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17212152 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0240s; samplesPerSecond = 53429.1
09/06/2016 12:25:49: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15995256 * 10000; EvalClassificationError = 0.07600000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.181557s
09/06/2016 12:25:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.33'

09/06/2016 12:25:49: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:49: Starting minibatch loop.
09/06/2016 12:25:49:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13921938 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0183s; samplesPerSecond = 69884.3
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16276331 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0213s; samplesPerSecond = 60046.0
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17090068 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14848137 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53596.9
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16527195 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0240s; samplesPerSecond = 53409.0
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17159867 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0213s; samplesPerSecond = 60108.0
09/06/2016 12:25:50:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16636944 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0213s; samplesPerSecond = 59986.9
09/06/2016 12:25:50: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15936174 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.177213s
09/06/2016 12:25:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.34'

09/06/2016 12:25:50: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:50: Starting minibatch loop.
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16906821 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0178s; samplesPerSecond = 71728.8
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14418758 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0240s; samplesPerSecond = 53413.5
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15848689 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53574.4
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16318011 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53440.2
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15352063 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0240s; samplesPerSecond = 53420.1
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14742370 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0240s; samplesPerSecond = 53411.2
09/06/2016 12:25:50:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16554413 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0239s; samplesPerSecond = 53453.6
09/06/2016 12:25:50: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15775406 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.185584s
09/06/2016 12:25:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.35'

09/06/2016 12:25:50: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:50: Starting minibatch loop.
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15373969 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0183s; samplesPerSecond = 69930.1
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19182336 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0213s; samplesPerSecond = 60116.5
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15158508 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0239s; samplesPerSecond = 53511.7
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15708618 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14619446 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0240s; samplesPerSecond = 53375.6
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13910179 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0239s; samplesPerSecond = 53467.0
09/06/2016 12:25:50:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15226822 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:50: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15698855 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.183403s
09/06/2016 12:25:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.36'

09/06/2016 12:25:50: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:50: Starting minibatch loop.
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17271128 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0236s; samplesPerSecond = 54212.0
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15075910 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0213s; samplesPerSecond = 60122.1
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15440271 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0213s; samplesPerSecond = 60000.9
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12932649 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0213s; samplesPerSecond = 60071.3
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16559262 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0239s; samplesPerSecond = 53552.0
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14702020 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:50:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16273041 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:50: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15447834 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.183432s
09/06/2016 12:25:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.37'

09/06/2016 12:25:50: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:50: Starting minibatch loop.
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17086862 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0209s; samplesPerSecond = 61170.8
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14715699 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14940417 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0187s; samplesPerSecond = 68566.5
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16454649 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0239s; samplesPerSecond = 53520.7
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14210191 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0239s; samplesPerSecond = 53458.1
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16033564 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53440.2
09/06/2016 12:25:50:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14252672 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:50: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15447957 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.183403s
09/06/2016 12:25:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.38'

09/06/2016 12:25:50: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:50: Starting minibatch loop.
09/06/2016 12:25:50:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15245637 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0236s; samplesPerSecond = 54278.7
09/06/2016 12:25:50:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14150614 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0240s; samplesPerSecond = 53411.2
09/06/2016 12:25:50:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15755613 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0239s; samplesPerSecond = 53451.4
09/06/2016 12:25:50:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15467634 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:51:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15592108 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:51:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17342644 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:51:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17978611 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0213s; samplesPerSecond = 60093.9
09/06/2016 12:25:51: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15823716 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.182573s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.39'

09/06/2016 12:25:51: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18975155 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0205s; samplesPerSecond = 62515.3
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14647381 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0239s; samplesPerSecond = 53513.9
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15599771 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0239s; samplesPerSecond = 53473.7
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15626054 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15985618 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0239s; samplesPerSecond = 53449.1
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16492434 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0240s; samplesPerSecond = 53429.1
09/06/2016 12:25:51:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14662266 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0240s; samplesPerSecond = 53406.8
09/06/2016 12:25:51: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15780449 * 10000; EvalClassificationError = 0.07550000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.184689s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.40'

09/06/2016 12:25:51: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16937305 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0178s; samplesPerSecond = 71712.7
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13820328 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0213s; samplesPerSecond = 60060.1
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15636744 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0239s; samplesPerSecond = 53599.1
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15901361 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0240s; samplesPerSecond = 53417.9
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15166650 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15241671 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:51:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15653992 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:51: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15444556 * 10000; EvalClassificationError = 0.07310000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.18296s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.41'

09/06/2016 12:25:51: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15034840 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0209s; samplesPerSecond = 61150.4
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14989798 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0239s; samplesPerSecond = 53446.9
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15917435 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0213s; samplesPerSecond = 60029.1
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15578203 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0240s; samplesPerSecond = 53417.9
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16280818 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0213s; samplesPerSecond = 60034.7
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16846323 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0239s; samplesPerSecond = 53635.0
09/06/2016 12:25:51:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17319469 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0240s; samplesPerSecond = 53415.7
09/06/2016 12:25:51: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15898705 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.183425s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.42'

09/06/2016 12:25:51: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16630217 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0196s; samplesPerSecond = 65276.1
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13294576 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0240s; samplesPerSecond = 53406.8
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15917583 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15790648 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53326.7
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16472111 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0239s; samplesPerSecond = 53480.4
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14034090 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0239s; samplesPerSecond = 53623.8
09/06/2016 12:25:51:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16956015 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:51: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15555933 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.187367s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.43'

09/06/2016 12:25:51: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16926413 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0183s; samplesPerSecond = 69937.7
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16363897 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0213s; samplesPerSecond = 60034.7
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13639555 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0239s; samplesPerSecond = 53478.2
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16664805 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0239s; samplesPerSecond = 53518.4
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16281080 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0239s; samplesPerSecond = 53462.5
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13564296 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0240s; samplesPerSecond = 53426.8
09/06/2016 12:25:51:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16526623 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0240s; samplesPerSecond = 53433.5
09/06/2016 12:25:51: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15709537 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.183427s
09/06/2016 12:25:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.44'

09/06/2016 12:25:51: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:51: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16758128 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0209s; samplesPerSecond = 61150.4
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14725612 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0239s; samplesPerSecond = 53451.4
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16129522 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16227765 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0213s; samplesPerSecond = 60065.7
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15812397 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0213s; samplesPerSecond = 60009.4
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14453859 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0239s; samplesPerSecond = 53487.1
09/06/2016 12:25:52:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15846949 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0240s; samplesPerSecond = 53429.1
09/06/2016 12:25:52: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15527948 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.182571s
09/06/2016 12:25:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.45'

09/06/2016 12:25:52: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:52: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13163276 * 1280; EvalClassificationError = 0.05625000 * 1280; time = 0.0204s; samplesPerSecond = 62732.8
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17128520 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15425162 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0213s; samplesPerSecond = 60057.2
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15192242 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0239s; samplesPerSecond = 53453.6
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16164570 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0213s; samplesPerSecond = 59970.0
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16738505 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0243s; samplesPerSecond = 52683.6
09/06/2016 12:25:52:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16348038 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0236s; samplesPerSecond = 54239.6
09/06/2016 12:25:52: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15742201 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.179424s
09/06/2016 12:25:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.46'

09/06/2016 12:25:52: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:52: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16164525 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0204s; samplesPerSecond = 62637.6
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16455059 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53380.0
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16870224 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0239s; samplesPerSecond = 53462.5
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12883611 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0240s; samplesPerSecond = 53400.1
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14594216 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0240s; samplesPerSecond = 53431.3
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15981717 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0239s; samplesPerSecond = 53578.9
09/06/2016 12:25:52:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14501266 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0240s; samplesPerSecond = 53442.4
09/06/2016 12:25:52: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.15290601 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.188205s
09/06/2016 12:25:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.47'

09/06/2016 12:25:52: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:52: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16257966 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0183s; samplesPerSecond = 70018.1
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16322243 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0240s; samplesPerSecond = 53393.4
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16032901 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0213s; samplesPerSecond = 60164.5
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15169969 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0240s; samplesPerSecond = 53404.5
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15752759 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0239s; samplesPerSecond = 53455.8
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14941444 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0239s; samplesPerSecond = 53527.4
09/06/2016 12:25:52:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14432421 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0240s; samplesPerSecond = 53404.5
09/06/2016 12:25:52: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15491803 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.183413s
09/06/2016 12:25:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.48'

09/06/2016 12:25:52: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:52: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16991386 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0209s; samplesPerSecond = 61150.4
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15043976 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0213s; samplesPerSecond = 60057.2
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16458762 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15567193 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0213s; samplesPerSecond = 60088.3
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14840393 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0239s; samplesPerSecond = 53449.1
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15142746 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0239s; samplesPerSecond = 53520.7
09/06/2016 12:25:52:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19236517 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0240s; samplesPerSecond = 53435.8
09/06/2016 12:25:52: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16079432 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.183426s
09/06/2016 12:25:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.49'

09/06/2016 12:25:52: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:52: Starting minibatch loop.
09/06/2016 12:25:52:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15400987 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0183s; samplesPerSecond = 70113.9
09/06/2016 12:25:52:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14237220 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0213s; samplesPerSecond = 60091.1
09/06/2016 12:25:52:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15252087 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16386962 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14503121 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0239s; samplesPerSecond = 53536.3
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16062884 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0240s; samplesPerSecond = 53424.6
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15499449 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0239s; samplesPerSecond = 53446.9
09/06/2016 12:25:53: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15345076 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.18343s
09/06/2016 12:25:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn'
09/06/2016 12:25:53: CNTKCommandTrainEnd: Simple_Demo

09/06/2016 12:25:53: Action "train" complete.


09/06/2016 12:25:53: ##############################################################################
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: # Action "write"                                                             #
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

09/06/2016 12:25:53: Action "write" complete.

09/06/2016 12:25:53: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/eldak/repo/cntk_github/CNTK/build/release/bin/cntk configFile=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Sep  6 2016 12:09:53
		Last modified date: Tue Sep  6 12:03:39 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-5.0
		Build Branch: eldak/deterministicCPU2
		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
		Built by eldak on atleneu04
		Build Path: /home/eldak/repo/cntk_github/CNTK
-------------------------------------------------------------------
Changed current directory to /home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
09/06/2016 12:25:53: -------------------------------------------------------------------
09/06/2016 12:25:53: Build info: 

09/06/2016 12:25:53: 		Built time: Sep  6 2016 12:09:53
09/06/2016 12:25:53: 		Last modified date: Tue Sep  6 12:03:39 2016
09/06/2016 12:25:53: 		Build type: release
09/06/2016 12:25:53: 		Build target: GPU
09/06/2016 12:25:53: 		With 1bit-SGD: no
09/06/2016 12:25:53: 		Math lib: mkl
09/06/2016 12:25:53: 		CUDA_PATH: /usr/local/cuda-7.5
09/06/2016 12:25:53: 		CUB_PATH: /usr/local/cub-1.4.1
09/06/2016 12:25:53: 		CUDNN_PATH: /usr/local/cudnn-5.0
09/06/2016 12:25:53: 		Build Branch: eldak/deterministicCPU2
09/06/2016 12:25:53: 		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
09/06/2016 12:25:53: 		Built by eldak on atleneu04
09/06/2016 12:25:53: 		Build Path: /home/eldak/repo/cntk_github/CNTK
09/06/2016 12:25:53: -------------------------------------------------------------------
09/06/2016 12:25:53: -------------------------------------------------------------------
09/06/2016 12:25:53: GPU info:

09/06/2016 12:25:53: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2045 MB
09/06/2016 12:25:53: -------------------------------------------------------------------

09/06/2016 12:25:53: Running on localhost at 2016/09/06 12:25:53
09/06/2016 12:25:53: Command line: 
/home/eldak/repo/cntk_github/CNTK/build/release/bin/cntk  configFile=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu  DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true


Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/eldak/repo/cntk_github/CNTK/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
09/06/2016 12:25:53: Commands: Simple_Demo Simple_Demo_Output
09/06/2016 12:25:53: Precision = "float"
09/06/2016 12:25:53: forceDeterministcAlgorithms flag is specified. Using 1 CPU thread.
09/06/2016 12:25:53: CNTKModelPath: /tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn
09/06/2016 12:25:53: CNTKCommandTrainInfo: Simple_Demo : 50
09/06/2016 12:25:53: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

09/06/2016 12:25:53: ##############################################################################
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: # Action "train"                                                             #
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: ##############################################################################

09/06/2016 12:25:53: CNTKCommandTrainBegin: Simple_Demo

09/06/2016 12:25:53: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn.49'.
SimpleNetworkBuilder Using CPU

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

09/06/2016 12:25:53: Loaded model with 25 nodes on CPU.

09/06/2016 12:25:53: Training criterion node(s):
09/06/2016 12:25:53: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

09/06/2016 12:25:53: Evaluation criterion node(s):
09/06/2016 12:25:53: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }


09/06/2016 12:25:53: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

09/06/2016 12:25:53: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:25:53: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:25:53: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
09/06/2016 12:25:53: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
09/06/2016 12:25:53: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
09/06/2016 12:25:53: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

09/06/2016 12:25:53: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

09/06/2016 12:25:53: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:25:53: Starting minibatch loop.
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.15400984 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0284s; samplesPerSecond = 45108.5
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.14237220 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0109s; samplesPerSecond = 117098.2
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15252085 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0105s; samplesPerSecond = 121488.2
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.16386957 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0102s; samplesPerSecond = 125428.7
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.14503121 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0099s; samplesPerSecond = 129201.6
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.16062884 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0096s; samplesPerSecond = 132959.4
09/06/2016 12:25:53:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.15499449 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0094s; samplesPerSecond = 135665.1
09/06/2016 12:25:53: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15345074 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.09895s
09/06/2016 12:25:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/models/simple.dnn'
09/06/2016 12:25:53: CNTKCommandTrainEnd: Simple_Demo

09/06/2016 12:25:53: Action "train" complete.


09/06/2016 12:25:53: ##############################################################################
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: # Action "write"                                                             #
09/06/2016 12:25:53: #                                                                            #
09/06/2016 12:25:53: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160906122543.36943/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

09/06/2016 12:25:53: Action "write" complete.

09/06/2016 12:25:53: __COMPLETED__