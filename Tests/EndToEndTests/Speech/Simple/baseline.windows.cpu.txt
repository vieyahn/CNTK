CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz
    Hardware threads: 24
    Total Memory: 33476764 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/repo/cntk_github/CNTK/x64/release/cntk.exe configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Sep  6 2016 12:59:12
		Last modified date: Tue Sep  6 12:47:32 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\local\cudnn-7.5-windows10-x64-v5.1\cuda
		Build Branch: eldak/deterministicCPU2
		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
09/06/2016 12:18:47: -------------------------------------------------------------------
09/06/2016 12:18:47: Build info: 

09/06/2016 12:18:47: 		Built time: Sep  6 2016 12:59:12
09/06/2016 12:18:47: 		Last modified date: Tue Sep  6 12:47:32 2016
09/06/2016 12:18:47: 		Build type: Release
09/06/2016 12:18:47: 		Build target: GPU
09/06/2016 12:18:47: 		With 1bit-SGD: yes
09/06/2016 12:18:47: 		Math lib: mkl
09/06/2016 12:18:47: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
09/06/2016 12:18:47: 		CUB_PATH: c:\Tools\cub-1.4.1\
09/06/2016 12:18:47: 		CUDNN_PATH: c:\local\cudnn-7.5-windows10-x64-v5.1\cuda
09/06/2016 12:18:47: 		Build Branch: eldak/deterministicCPU2
09/06/2016 12:18:47: 		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
09/06/2016 12:18:47: 		Built by eldak on ELDAK-0
09/06/2016 12:18:47: 		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
09/06/2016 12:18:47: -------------------------------------------------------------------
09/06/2016 12:18:48: -------------------------------------------------------------------
09/06/2016 12:18:48: GPU info:

09/06/2016 12:18:48: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2048 MB
09/06/2016 12:18:48: 		Device[1]: cores = 576; computeCapability = 5.0; type = "Quadro K620"; memory = 2048 MB
09/06/2016 12:18:48: -------------------------------------------------------------------

09/06/2016 12:18:48: Running on ELDAK-0 at 2016/09/06 12:18:48
09/06/2016 12:18:48: Command line: 
C:\repo\cntk_github\CNTK\x64\release\cntk.exe  configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu  DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple  OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true


Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
09/06/2016 12:18:48: Commands: Simple_Demo Simple_Demo_Output
09/06/2016 12:18:48: Precision = "float"
09/06/2016 12:18:48: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn
09/06/2016 12:18:48: CNTKCommandTrainInfo: Simple_Demo : 50
09/06/2016 12:18:48: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

09/06/2016 12:18:48: ##############################################################################
09/06/2016 12:18:48: #                                                                            #
09/06/2016 12:18:48: # Action "train"                                                             #
09/06/2016 12:18:48: #                                                                            #
09/06/2016 12:18:48: ##############################################################################

09/06/2016 12:18:48: CNTKCommandTrainBegin: Simple_Demo

09/06/2016 12:18:48: Creating virgin network.
SimpleNetworkBuilder Using CPU
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, init dims=[50 x 2], range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, init dims=[50 x 50], range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, init dims=[2 x 50], range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

09/06/2016 12:18:48: Created model with 25 nodes on CPU.

09/06/2016 12:18:48: Training criterion node(s):
09/06/2016 12:18:48: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

09/06/2016 12:18:48: Evaluation criterion node(s):
09/06/2016 12:18:48: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }


09/06/2016 12:18:48: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

09/06/2016 12:18:48: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:18:48: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:18:48: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
09/06/2016 12:18:48: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
09/06/2016 12:18:48: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
09/06/2016 12:18:48: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


09/06/2016 12:18:48: Precomputing --> 3 PreCompute nodes found.

09/06/2016 12:18:48: 	MeanOfFeatures = Mean()
09/06/2016 12:18:48: 	InvStdOfFeatures = InvStdDev()
09/06/2016 12:18:48: 	Prior = Mean()

09/06/2016 12:18:48: Precomputing --> Completed.


09/06/2016 12:18:48: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:48: Starting minibatch loop.
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84135876 * 1280; EvalClassificationError = 0.49375000 * 1280; time = 0.0776s; samplesPerSecond = 16495.7
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.80750942 * 1280; EvalClassificationError = 0.50937500 * 1280; time = 0.0665s; samplesPerSecond = 19237.7
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.73671188 * 1280; EvalClassificationError = 0.48828125 * 1280; time = 0.0666s; samplesPerSecond = 19220.7
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71652222 * 1280; EvalClassificationError = 0.51484375 * 1280; time = 0.0641s; samplesPerSecond = 19954.5
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70134087 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0634s; samplesPerSecond = 20202.3
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71664810 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0592s; samplesPerSecond = 21623.1
09/06/2016 12:18:48:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.71382103 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0597s; samplesPerSecond = 21431.2
09/06/2016 12:18:48: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.74341201 * 10000; EvalClassificationError = 0.50260000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.51013s
09/06/2016 12:18:48: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.1'

09/06/2016 12:18:48: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:48: Starting minibatch loop.
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71325479 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0613s; samplesPerSecond = 20864.2
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.75389848 * 1280; EvalClassificationError = 0.46406250 * 1280; time = 0.0619s; samplesPerSecond = 20676.8
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.75757513 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0589s; samplesPerSecond = 21749.5
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75674992 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0591s; samplesPerSecond = 21645.4
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74725094 * 1280; EvalClassificationError = 0.50390625 * 1280; time = 0.0610s; samplesPerSecond = 20977.8
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.73079414 * 1280; EvalClassificationError = 0.50546875 * 1280; time = 0.0620s; samplesPerSecond = 20651.5
09/06/2016 12:18:49:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73625755 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0611s; samplesPerSecond = 20935.9
09/06/2016 12:18:49: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73900103 * 10000; EvalClassificationError = 0.49680000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.478764s
09/06/2016 12:18:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.2'

09/06/2016 12:18:49: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:49: Starting minibatch loop.
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.74044714 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0631s; samplesPerSecond = 20300.1
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73792162 * 1280; EvalClassificationError = 0.50625000 * 1280; time = 0.0617s; samplesPerSecond = 20748.6
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.77087250 * 1280; EvalClassificationError = 0.52187500 * 1280; time = 0.0616s; samplesPerSecond = 20795.1
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75999603 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0606s; samplesPerSecond = 21106.1
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73512688 * 1280; EvalClassificationError = 0.50937500 * 1280; time = 0.0624s; samplesPerSecond = 20525.6
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71369209 * 1280; EvalClassificationError = 0.48984375 * 1280; time = 0.0604s; samplesPerSecond = 21183.6
09/06/2016 12:18:49:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69696960 * 1280; EvalClassificationError = 0.50703125 * 1280; time = 0.0622s; samplesPerSecond = 20594.3
09/06/2016 12:18:49: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.73257485 * 10000; EvalClassificationError = 0.50380000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.484856s
09/06/2016 12:18:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.3'

09/06/2016 12:18:49: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:49: Starting minibatch loop.
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71515269 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0609s; samplesPerSecond = 21005.0
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74560342 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0602s; samplesPerSecond = 21251.9
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.73897266 * 1280; EvalClassificationError = 0.47812500 * 1280; time = 0.0619s; samplesPerSecond = 20682.2
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71412621 * 1280; EvalClassificationError = 0.48671875 * 1280; time = 0.0609s; samplesPerSecond = 21012.2
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71213531 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0622s; samplesPerSecond = 20577.1
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70156898 * 1280; EvalClassificationError = 0.50390625 * 1280; time = 0.0639s; samplesPerSecond = 20028.5
09/06/2016 12:18:50:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70737991 * 1280; EvalClassificationError = 0.49687500 * 1280; time = 0.0630s; samplesPerSecond = 20309.4
09/06/2016 12:18:50: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.71707466 * 10000; EvalClassificationError = 0.49440000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.487305s
09/06/2016 12:18:50: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.4'

09/06/2016 12:18:50: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:50: Starting minibatch loop.
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69854631 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0617s; samplesPerSecond = 20738.1
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70018864 * 1280; EvalClassificationError = 0.49140625 * 1280; time = 0.0627s; samplesPerSecond = 20425.4
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69679499 * 1280; EvalClassificationError = 0.51796875 * 1280; time = 0.0621s; samplesPerSecond = 20599.6
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69342022 * 1280; EvalClassificationError = 0.49531250 * 1280; time = 0.0628s; samplesPerSecond = 20374.1
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69504795 * 1280; EvalClassificationError = 0.48906250 * 1280; time = 0.0628s; samplesPerSecond = 20387.0
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70215073 * 1280; EvalClassificationError = 0.48593750 * 1280; time = 0.0616s; samplesPerSecond = 20778.5
09/06/2016 12:18:50:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69844513 * 1280; EvalClassificationError = 0.47734375 * 1280; time = 0.0631s; samplesPerSecond = 20284.0
09/06/2016 12:18:50: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.69761074 * 10000; EvalClassificationError = 0.49640000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.492014s
09/06/2016 12:18:50: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.5'

09/06/2016 12:18:50: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:50: Starting minibatch loop.
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70235581 * 1280; EvalClassificationError = 0.49843750 * 1280; time = 0.0657s; samplesPerSecond = 19470.3
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69492173 * 1280; EvalClassificationError = 0.46875000 * 1280; time = 0.0636s; samplesPerSecond = 20118.8
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.68310499 * 1280; EvalClassificationError = 0.49062500 * 1280; time = 0.0621s; samplesPerSecond = 20628.5
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.68260880 * 1280; EvalClassificationError = 0.50625000 * 1280; time = 0.0605s; samplesPerSecond = 21162.3
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.55142403 * 1280; EvalClassificationError = 0.29218750 * 1280; time = 0.0638s; samplesPerSecond = 20054.8
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.26587105 * 1280; EvalClassificationError = 0.10390625 * 1280; time = 0.0606s; samplesPerSecond = 21106.1
09/06/2016 12:18:51:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17692909 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0632s; samplesPerSecond = 20257.0
09/06/2016 12:18:51: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.49748428 * 10000; EvalClassificationError = 0.31920000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.494818s
09/06/2016 12:18:51: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.6'

09/06/2016 12:18:51: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:51: Starting minibatch loop.
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17653137 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0626s; samplesPerSecond = 20455.8
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17294592 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0629s; samplesPerSecond = 20356.9
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17373481 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0607s; samplesPerSecond = 21071.0
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16362071 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0617s; samplesPerSecond = 20756.6
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16035757 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0617s; samplesPerSecond = 20739.8
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19017677 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0646s; samplesPerSecond = 19811.2
09/06/2016 12:18:51:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17996988 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0631s; samplesPerSecond = 20297.5
09/06/2016 12:18:51: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17464330 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.490984s
09/06/2016 12:18:51: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.7'

09/06/2016 12:18:51: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:51: Starting minibatch loop.
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17758296 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0642s; samplesPerSecond = 19952.6
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16837685 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0607s; samplesPerSecond = 21083.8
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17160821 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0650s; samplesPerSecond = 19700.2
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16443963 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0647s; samplesPerSecond = 19773.5
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17230077 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0610s; samplesPerSecond = 20993.2
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19414730 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0612s; samplesPerSecond = 20922.9
09/06/2016 12:18:52:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15372448 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0653s; samplesPerSecond = 19588.9
09/06/2016 12:18:52: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17304763 * 10000; EvalClassificationError = 0.07940000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.495876s
09/06/2016 12:18:52: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.8'

09/06/2016 12:18:52: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:52: Starting minibatch loop.
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21021349 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0636s; samplesPerSecond = 20111.2
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20793064 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0655s; samplesPerSecond = 19535.7
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19795485 * 1280; EvalClassificationError = 0.09609375 * 1280; time = 0.0638s; samplesPerSecond = 20067.4
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19360495 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0622s; samplesPerSecond = 20578.1
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18502398 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0656s; samplesPerSecond = 19510.7
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17273159 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0611s; samplesPerSecond = 20955.4
09/06/2016 12:18:52:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17065516 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0624s; samplesPerSecond = 20507.6
09/06/2016 12:18:52: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.19136704 * 10000; EvalClassificationError = 0.08190000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.499615s
09/06/2016 12:18:52: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.9'

09/06/2016 12:18:52: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:52: Starting minibatch loop.
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19245687 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0648s; samplesPerSecond = 19745.2
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15463991 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0630s; samplesPerSecond = 20331.0
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17308302 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0657s; samplesPerSecond = 19485.2
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15397019 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0612s; samplesPerSecond = 20931.8
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.22222414 * 1280; EvalClassificationError = 0.09687500 * 1280; time = 0.0643s; samplesPerSecond = 19891.5
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17288752 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0660s; samplesPerSecond = 19388.9
09/06/2016 12:18:53:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18737612 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0659s; samplesPerSecond = 19433.4
09/06/2016 12:18:53: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.17765856 * 10000; EvalClassificationError = 0.07910000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.506501s
09/06/2016 12:18:53: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.10'

09/06/2016 12:18:53: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:53: Starting minibatch loop.
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18579458 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0639s; samplesPerSecond = 20029.4
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16313087 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0655s; samplesPerSecond = 19551.8
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16649194 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0673s; samplesPerSecond = 19028.4
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16162486 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0628s; samplesPerSecond = 20391.9
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15486541 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0629s; samplesPerSecond = 20350.4
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14946566 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0652s; samplesPerSecond = 19638.8
09/06/2016 12:18:53:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14349651 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0625s; samplesPerSecond = 20466.2
09/06/2016 12:18:54: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16353757 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.505271s
09/06/2016 12:18:54: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.11'

09/06/2016 12:18:54: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:54: Starting minibatch loop.
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19283112 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0659s; samplesPerSecond = 19416.0
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16869527 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0663s; samplesPerSecond = 19307.6
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17596116 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0670s; samplesPerSecond = 19109.9
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17765641 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0647s; samplesPerSecond = 19780.3
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15841799 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0621s; samplesPerSecond = 20597.7
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16586752 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0655s; samplesPerSecond = 19532.4
09/06/2016 12:18:54:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14362717 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0648s; samplesPerSecond = 19740.0
09/06/2016 12:18:54: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16872913 * 10000; EvalClassificationError = 0.08020000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.513822s
09/06/2016 12:18:54: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.12'

09/06/2016 12:18:54: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:54: Starting minibatch loop.
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15137086 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0673s; samplesPerSecond = 19012.0
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18014736 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0659s; samplesPerSecond = 19432.8
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18233676 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0654s; samplesPerSecond = 19573.1
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14710093 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0658s; samplesPerSecond = 19465.3
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16798220 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0669s; samplesPerSecond = 19127.0
09/06/2016 12:18:54:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17125435 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0688s; samplesPerSecond = 18611.4
09/06/2016 12:18:55:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15528488 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0694s; samplesPerSecond = 18431.3
09/06/2016 12:18:55: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16557423 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.524711s
09/06/2016 12:18:55: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.13'

09/06/2016 12:18:55: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:55: Starting minibatch loop.
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21908119 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0672s; samplesPerSecond = 19040.0
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21171634 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0645s; samplesPerSecond = 19835.4
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22922959 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0661s; samplesPerSecond = 19372.5
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.24514408 * 1280; EvalClassificationError = 0.09687500 * 1280; time = 0.0641s; samplesPerSecond = 19953.5
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20996237 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0659s; samplesPerSecond = 19424.0
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15948563 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0666s; samplesPerSecond = 19218.4
09/06/2016 12:18:55:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16170378 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0636s; samplesPerSecond = 20139.7
09/06/2016 12:18:55: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.20099924 * 10000; EvalClassificationError = 0.08080000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.516949s
09/06/2016 12:18:55: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.14'

09/06/2016 12:18:55: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:55: Starting minibatch loop.
09/06/2016 12:18:55:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16885355 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0667s; samplesPerSecond = 19190.1
09/06/2016 12:18:55:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14227781 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0642s; samplesPerSecond = 19935.5
09/06/2016 12:18:55:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17880189 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0669s; samplesPerSecond = 19141.0
09/06/2016 12:18:55:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16684999 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0663s; samplesPerSecond = 19295.7
09/06/2016 12:18:55:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18277488 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0654s; samplesPerSecond = 19568.9
09/06/2016 12:18:56:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16113520 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0696s; samplesPerSecond = 18386.3
09/06/2016 12:18:56:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15518932 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0679s; samplesPerSecond = 18841.3
09/06/2016 12:18:56: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16385691 * 10000; EvalClassificationError = 0.07490000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.522998s
09/06/2016 12:18:56: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.15'

09/06/2016 12:18:56: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:56: Starting minibatch loop.
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16828589 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0672s; samplesPerSecond = 19039.7
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15316296 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0666s; samplesPerSecond = 19210.3
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18217859 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0669s; samplesPerSecond = 19127.9
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19777842 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0668s; samplesPerSecond = 19154.2
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19906125 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0673s; samplesPerSecond = 19022.1
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19654007 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0676s; samplesPerSecond = 18929.0
09/06/2016 12:18:56:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21218643 * 1280; EvalClassificationError = 0.09921875 * 1280; time = 0.0650s; samplesPerSecond = 19683.8
09/06/2016 12:18:56: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.18791464 * 10000; EvalClassificationError = 0.08360000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.523725s
09/06/2016 12:18:56: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.16'

09/06/2016 12:18:56: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:56: Starting minibatch loop.
09/06/2016 12:18:56:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18653588 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0684s; samplesPerSecond = 18711.0
09/06/2016 12:18:56:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19363379 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0676s; samplesPerSecond = 18943.9
09/06/2016 12:18:56:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20845547 * 1280; EvalClassificationError = 0.09531250 * 1280; time = 0.0702s; samplesPerSecond = 18222.7
09/06/2016 12:18:56:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17155900 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0674s; samplesPerSecond = 18988.0
09/06/2016 12:18:57:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17113748 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0636s; samplesPerSecond = 20118.5
09/06/2016 12:18:57:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17136288 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0663s; samplesPerSecond = 19307.6
09/06/2016 12:18:57:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16961527 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0677s; samplesPerSecond = 18901.6
09/06/2016 12:18:57: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.18149427 * 10000; EvalClassificationError = 0.08230000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.529104s
09/06/2016 12:18:57: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.17'

09/06/2016 12:18:57: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:57: Starting minibatch loop.
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15841733 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0658s; samplesPerSecond = 19451.1
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16292464 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0678s; samplesPerSecond = 18883.0
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16793272 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0694s; samplesPerSecond = 18439.3
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15810738 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0671s; samplesPerSecond = 19081.1
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15217614 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0696s; samplesPerSecond = 18394.8
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15943284 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0689s; samplesPerSecond = 18566.3
09/06/2016 12:18:57:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15780420 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0660s; samplesPerSecond = 19398.3
09/06/2016 12:18:57: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980190 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.534183s
09/06/2016 12:18:57: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.18'

09/06/2016 12:18:57: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:57: Starting minibatch loop.
09/06/2016 12:18:57:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15392799 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0667s; samplesPerSecond = 19178.6
09/06/2016 12:18:57:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14661627 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0672s; samplesPerSecond = 19060.7
09/06/2016 12:18:57:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16554856 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0650s; samplesPerSecond = 19684.4
09/06/2016 12:18:58:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15092454 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0670s; samplesPerSecond = 19104.2
09/06/2016 12:18:58:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18197446 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0682s; samplesPerSecond = 18759.0
09/06/2016 12:18:58:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16238856 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0680s; samplesPerSecond = 18820.8
09/06/2016 12:18:58:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17169094 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0666s; samplesPerSecond = 19215.8
09/06/2016 12:18:58: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16259879 * 10000; EvalClassificationError = 0.07790000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.52578s
09/06/2016 12:18:58: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.19'

09/06/2016 12:18:58: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:58: Starting minibatch loop.
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16124450 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0690s; samplesPerSecond = 18550.7
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16558851 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0663s; samplesPerSecond = 19305.3
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16220961 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0686s; samplesPerSecond = 18669.8
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17389975 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0686s; samplesPerSecond = 18658.3
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16840796 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0697s; samplesPerSecond = 18370.7
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15880718 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0689s; samplesPerSecond = 18582.5
09/06/2016 12:18:58:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16730919 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0674s; samplesPerSecond = 18982.9
09/06/2016 12:18:58: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16363756 * 10000; EvalClassificationError = 0.07690000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.537549s
09/06/2016 12:18:58: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.20'

09/06/2016 12:18:58: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:58: Starting minibatch loop.
09/06/2016 12:18:58:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16340449 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0696s; samplesPerSecond = 18380.5
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14519358 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0679s; samplesPerSecond = 18861.8
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15791724 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0680s; samplesPerSecond = 18813.6
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14244428 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0687s; samplesPerSecond = 18630.9
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16051393 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0663s; samplesPerSecond = 19298.9
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16649289 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0674s; samplesPerSecond = 18991.4
09/06/2016 12:18:59:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16313982 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0678s; samplesPerSecond = 18879.3
09/06/2016 12:18:59: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15771991 * 10000; EvalClassificationError = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.533088s
09/06/2016 12:18:59: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.21'

09/06/2016 12:18:59: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:59: Starting minibatch loop.
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15215003 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0700s; samplesPerSecond = 18291.2
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13743010 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0659s; samplesPerSecond = 19421.6
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16301706 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0699s; samplesPerSecond = 18323.4
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16211681 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0685s; samplesPerSecond = 18673.0
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15394626 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0673s; samplesPerSecond = 19025.0
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14863129 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0669s; samplesPerSecond = 19128.7
09/06/2016 12:18:59:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18063536 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0667s; samplesPerSecond = 19194.7
09/06/2016 12:18:59: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15907111 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.5355s
09/06/2016 12:18:59: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.22'

09/06/2016 12:18:59: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:18:59: Starting minibatch loop.
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17805440 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0720s; samplesPerSecond = 17777.3
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17195385 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0677s; samplesPerSecond = 18900.0
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15114913 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0702s; samplesPerSecond = 18226.9
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17855206 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0683s; samplesPerSecond = 18741.4
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15491066 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0688s; samplesPerSecond = 18612.0
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16576710 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0692s; samplesPerSecond = 18484.3
09/06/2016 12:19:00:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15395460 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0684s; samplesPerSecond = 18714.5
09/06/2016 12:19:00: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16409805 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.545117s
09/06/2016 12:19:00: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.23'

09/06/2016 12:19:00: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:00: Starting minibatch loop.
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16398238 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0711s; samplesPerSecond = 18002.3
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17477299 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0678s; samplesPerSecond = 18883.0
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14503856 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0680s; samplesPerSecond = 18817.2
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12699919 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0673s; samplesPerSecond = 19026.4
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18087120 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0684s; samplesPerSecond = 18710.7
09/06/2016 12:19:00:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13315372 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0710s; samplesPerSecond = 18028.7
09/06/2016 12:19:01:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15526733 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0704s; samplesPerSecond = 18175.4
09/06/2016 12:19:01: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15478525 * 10000; EvalClassificationError = 0.07420000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.547215s
09/06/2016 12:19:01: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.24'

09/06/2016 12:19:01: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:01: Starting minibatch loop.
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13737727 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0690s; samplesPerSecond = 18540.2
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17392000 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0696s; samplesPerSecond = 18396.9
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14000225 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0705s; samplesPerSecond = 18153.2
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15248556 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0713s; samplesPerSecond = 17955.3
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17012677 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0705s; samplesPerSecond = 18158.6
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17270203 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0705s; samplesPerSecond = 18157.6
09/06/2016 12:19:01:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18479738 * 1280; EvalClassificationError = 0.10078125 * 1280; time = 0.0686s; samplesPerSecond = 18648.3
09/06/2016 12:19:01: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16431788 * 10000; EvalClassificationError = 0.08380000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.550509s
09/06/2016 12:19:01: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.25'

09/06/2016 12:19:01: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:01: Starting minibatch loop.
09/06/2016 12:19:01:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17245731 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0742s; samplesPerSecond = 17259.5
09/06/2016 12:19:01:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21459775 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0714s; samplesPerSecond = 17939.7
09/06/2016 12:19:01:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16779342 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0696s; samplesPerSecond = 18400.1
09/06/2016 12:19:01:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15446692 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0678s; samplesPerSecond = 18868.2
09/06/2016 12:19:01:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16801815 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0699s; samplesPerSecond = 18308.2
09/06/2016 12:19:02:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12417126 * 1280; EvalClassificationError = 0.05312500 * 1280; time = 0.0699s; samplesPerSecond = 18317.6
09/06/2016 12:19:02:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16505804 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0700s; samplesPerSecond = 18288.3
09/06/2016 12:19:02: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16584508 * 10000; EvalClassificationError = 0.08000000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.552153s
09/06/2016 12:19:02: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.26'

09/06/2016 12:19:02: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:02: Starting minibatch loop.
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16579037 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0699s; samplesPerSecond = 18323.7
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16928740 * 1280; EvalClassificationError = 0.09296875 * 1280; time = 0.0706s; samplesPerSecond = 18127.7
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14732041 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0701s; samplesPerSecond = 18262.5
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16394129 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0684s; samplesPerSecond = 18704.7
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17036233 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0693s; samplesPerSecond = 18476.8
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16040354 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0699s; samplesPerSecond = 18316.3
09/06/2016 12:19:02:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17108250 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0739s; samplesPerSecond = 17313.7
09/06/2016 12:19:02: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16273871 * 10000; EvalClassificationError = 0.07960000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.553181s
09/06/2016 12:19:02: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.27'

09/06/2016 12:19:02: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:02: Starting minibatch loop.
09/06/2016 12:19:02:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15705372 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0698s; samplesPerSecond = 18336.0
09/06/2016 12:19:02:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16088928 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0707s; samplesPerSecond = 18107.5
09/06/2016 12:19:02:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16610055 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0709s; samplesPerSecond = 18065.3
09/06/2016 12:19:03:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14504981 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0704s; samplesPerSecond = 18185.7
09/06/2016 12:19:03:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14169722 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0714s; samplesPerSecond = 17920.4
09/06/2016 12:19:03:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15533619 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0713s; samplesPerSecond = 17955.3
09/06/2016 12:19:03:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16402044 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0700s; samplesPerSecond = 18273.4
09/06/2016 12:19:03: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15696592 * 10000; EvalClassificationError = 0.07980000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.557024s
09/06/2016 12:19:03: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.28'

09/06/2016 12:19:03: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:03: Starting minibatch loop.
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15680964 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0706s; samplesPerSecond = 18124.4
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13534009 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0713s; samplesPerSecond = 17958.4
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17445335 * 1280; EvalClassificationError = 0.09453125 * 1280; time = 0.0722s; samplesPerSecond = 17719.2
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14585710 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0705s; samplesPerSecond = 18148.3
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16541200 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0701s; samplesPerSecond = 18249.7
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14466286 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0736s; samplesPerSecond = 17400.3
09/06/2016 12:19:03:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16790562 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0710s; samplesPerSecond = 18020.6
09/06/2016 12:19:03: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16051628 * 10000; EvalClassificationError = 0.08080000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.56011s
09/06/2016 12:19:03: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.29'

09/06/2016 12:19:03: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:03: Starting minibatch loop.
09/06/2016 12:19:03:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15947018 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0724s; samplesPerSecond = 17684.4
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15094757 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0712s; samplesPerSecond = 17989.2
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14843731 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0720s; samplesPerSecond = 17787.9
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16837692 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0732s; samplesPerSecond = 17482.5
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15947418 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0695s; samplesPerSecond = 18410.1
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16039391 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0733s; samplesPerSecond = 17468.7
09/06/2016 12:19:04:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16297731 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0721s; samplesPerSecond = 17748.7
09/06/2016 12:19:04: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15705149 * 10000; EvalClassificationError = 0.08010000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.565943s
09/06/2016 12:19:04: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.30'

09/06/2016 12:19:04: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:04: Starting minibatch loop.
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16175013 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0722s; samplesPerSecond = 17731.5
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350082 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0718s; samplesPerSecond = 17822.6
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15346982 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0724s; samplesPerSecond = 17680.8
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14525995 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0704s; samplesPerSecond = 18172.3
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16925826 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0729s; samplesPerSecond = 17548.4
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13906126 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0708s; samplesPerSecond = 18070.2
09/06/2016 12:19:04:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15154276 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0725s; samplesPerSecond = 17655.9
09/06/2016 12:19:05: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15329951 * 10000; EvalClassificationError = 0.07800000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.565594s
09/06/2016 12:19:05: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.31'

09/06/2016 12:19:05: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:05: Starting minibatch loop.
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15780716 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0720s; samplesPerSecond = 17786.7
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14718451 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0730s; samplesPerSecond = 17546.0
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14815593 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0693s; samplesPerSecond = 18475.8
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15589581 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0709s; samplesPerSecond = 18050.8
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15080585 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0686s; samplesPerSecond = 18659.2
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15917301 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0727s; samplesPerSecond = 17610.0
09/06/2016 12:19:05:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15810490 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0701s; samplesPerSecond = 18268.2
09/06/2016 12:19:05: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15582455 * 10000; EvalClassificationError = 0.07920000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.559173s
09/06/2016 12:19:05: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.32'

09/06/2016 12:19:05: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:05: Starting minibatch loop.
09/06/2016 12:19:05:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16427889 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0715s; samplesPerSecond = 17891.6
09/06/2016 12:19:05:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17547863 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0715s; samplesPerSecond = 17893.1
09/06/2016 12:19:05:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15116785 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0752s; samplesPerSecond = 17026.5
09/06/2016 12:19:05:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15775800 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0672s; samplesPerSecond = 19047.3
09/06/2016 12:19:05:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13863611 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0729s; samplesPerSecond = 17568.4
09/06/2016 12:19:06:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14410172 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0714s; samplesPerSecond = 17918.4
09/06/2016 12:19:06:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16478224 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0716s; samplesPerSecond = 17882.6
09/06/2016 12:19:06: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15587469 * 10000; EvalClassificationError = 0.08000000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.563561s
09/06/2016 12:19:06: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.33'

09/06/2016 12:19:06: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:06: Starting minibatch loop.
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14666815 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0729s; samplesPerSecond = 17553.5
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15634019 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0714s; samplesPerSecond = 17931.9
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15692689 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0679s; samplesPerSecond = 18857.4
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14791536 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0717s; samplesPerSecond = 17858.9
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16619754 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0765s; samplesPerSecond = 16727.2
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16043940 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0734s; samplesPerSecond = 17431.6
09/06/2016 12:19:06:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15662022 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0726s; samplesPerSecond = 17635.7
09/06/2016 12:19:06: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15419413 * 10000; EvalClassificationError = 0.07940000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.568433s
09/06/2016 12:19:06: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.34'

09/06/2016 12:19:06: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:06: Starting minibatch loop.
09/06/2016 12:19:06:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16274959 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0746s; samplesPerSecond = 17164.8
09/06/2016 12:19:06:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14440039 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0694s; samplesPerSecond = 18456.8
09/06/2016 12:19:07:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14822292 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0750s; samplesPerSecond = 17056.0
09/06/2016 12:19:07:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14809823 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0703s; samplesPerSecond = 18210.0
09/06/2016 12:19:07:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14209609 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0733s; samplesPerSecond = 17465.6
09/06/2016 12:19:07:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14509535 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0684s; samplesPerSecond = 18715.1
09/06/2016 12:19:07:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15982723 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0732s; samplesPerSecond = 17493.3
09/06/2016 12:19:07: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15050690 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.566015s
09/06/2016 12:19:07: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.35'

09/06/2016 12:19:07: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:07: Starting minibatch loop.
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14914435 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0700s; samplesPerSecond = 18292.2
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17713274 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0715s; samplesPerSecond = 17904.6
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15502584 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0738s; samplesPerSecond = 17347.9
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15611315 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0748s; samplesPerSecond = 17119.4
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15262537 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0703s; samplesPerSecond = 18219.3
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13625097 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0722s; samplesPerSecond = 17722.1
09/06/2016 12:19:07:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14132137 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0714s; samplesPerSecond = 17939.5
09/06/2016 12:19:07: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15432595 * 10000; EvalClassificationError = 0.07960000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.568765s
09/06/2016 12:19:07: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.36'

09/06/2016 12:19:07: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:07: Starting minibatch loop.
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16839068 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0743s; samplesPerSecond = 17227.5
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14219899 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0702s; samplesPerSecond = 18229.2
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15073593 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0709s; samplesPerSecond = 18045.7
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12535233 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0731s; samplesPerSecond = 17521.0
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15706263 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0742s; samplesPerSecond = 17255.1
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14254761 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0730s; samplesPerSecond = 17528.0
09/06/2016 12:19:08:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16218557 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0758s; samplesPerSecond = 16882.8
09/06/2016 12:19:08: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14976548 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.575893s
09/06/2016 12:19:08: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.37'

09/06/2016 12:19:08: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:08: Starting minibatch loop.
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16853929 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0729s; samplesPerSecond = 17560.9
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14643590 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0717s; samplesPerSecond = 17862.4
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14096925 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0747s; samplesPerSecond = 17132.9
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16171236 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0735s; samplesPerSecond = 17409.8
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13762398 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0729s; samplesPerSecond = 17547.2
09/06/2016 12:19:08:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15780306 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0743s; samplesPerSecond = 17234.6
09/06/2016 12:19:09:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13847189 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0716s; samplesPerSecond = 17888.8
09/06/2016 12:19:09: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15008168 * 10000; EvalClassificationError = 0.07950000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.575975s
09/06/2016 12:19:09: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.38'

09/06/2016 12:19:09: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:09: Starting minibatch loop.
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14602553 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0749s; samplesPerSecond = 17084.2
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14157907 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0750s; samplesPerSecond = 17077.4
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15173781 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0741s; samplesPerSecond = 17262.5
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15480695 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0734s; samplesPerSecond = 17436.8
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16661687 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0718s; samplesPerSecond = 17821.1
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18570213 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0724s; samplesPerSecond = 17675.4
09/06/2016 12:19:09:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19003839 * 1280; EvalClassificationError = 0.09687500 * 1280; time = 0.0728s; samplesPerSecond = 17580.0
09/06/2016 12:19:09: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16018512 * 10000; EvalClassificationError = 0.08150000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.576804s
09/06/2016 12:19:09: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.39'

09/06/2016 12:19:09: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:09: Starting minibatch loop.
09/06/2016 12:19:09:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18146310 * 1280; EvalClassificationError = 0.09531250 * 1280; time = 0.0749s; samplesPerSecond = 17098.8
09/06/2016 12:19:09:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15083170 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0748s; samplesPerSecond = 17114.6
09/06/2016 12:19:09:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15692687 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0739s; samplesPerSecond = 17317.2
09/06/2016 12:19:09:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15858479 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0741s; samplesPerSecond = 17279.1
09/06/2016 12:19:10:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16058187 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0754s; samplesPerSecond = 16982.0
09/06/2016 12:19:10:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16116400 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0758s; samplesPerSecond = 16886.1
09/06/2016 12:19:10:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14260492 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0753s; samplesPerSecond = 16994.6
09/06/2016 12:19:10: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15674375 * 10000; EvalClassificationError = 0.07930000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.589158s
09/06/2016 12:19:10: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.40'

09/06/2016 12:19:10: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:10: Starting minibatch loop.
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16486689 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0749s; samplesPerSecond = 17098.6
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13254532 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0752s; samplesPerSecond = 17020.4
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14597421 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0727s; samplesPerSecond = 17597.9
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15060010 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0743s; samplesPerSecond = 17226.8
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14728065 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0738s; samplesPerSecond = 17350.5
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14452472 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0734s; samplesPerSecond = 17436.6
09/06/2016 12:19:10:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15255547 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0728s; samplesPerSecond = 17577.1
09/06/2016 12:19:10: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14737688 * 10000; EvalClassificationError = 0.07340000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.580457s
09/06/2016 12:19:10: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.41'

09/06/2016 12:19:10: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:10: Starting minibatch loop.
09/06/2016 12:19:10:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14049195 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0736s; samplesPerSecond = 17393.4
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14011940 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0718s; samplesPerSecond = 17829.5
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15300314 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0755s; samplesPerSecond = 16962.6
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14769540 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0737s; samplesPerSecond = 17369.6
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15723443 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0722s; samplesPerSecond = 17735.7
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15916705 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0709s; samplesPerSecond = 18062.5
09/06/2016 12:19:11:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18246584 * 1280; EvalClassificationError = 0.09687500 * 1280; time = 0.0748s; samplesPerSecond = 17119.4
09/06/2016 12:19:11: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15400232 * 10000; EvalClassificationError = 0.07960000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.576354s
09/06/2016 12:19:11: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.42'

09/06/2016 12:19:11: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:11: Starting minibatch loop.
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16289397 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0736s; samplesPerSecond = 17381.9
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12215725 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0752s; samplesPerSecond = 17013.8
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14745386 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0751s; samplesPerSecond = 17053.0
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15294027 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0745s; samplesPerSecond = 17176.1
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15700641 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0754s; samplesPerSecond = 16968.3
09/06/2016 12:19:11:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14175749 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0756s; samplesPerSecond = 16924.7
09/06/2016 12:19:12:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17108593 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0729s; samplesPerSecond = 17558.8
09/06/2016 12:19:12: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14958419 * 10000; EvalClassificationError = 0.07820000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.587223s
09/06/2016 12:19:12: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.43'

09/06/2016 12:19:12: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:12: Starting minibatch loop.
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16001981 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0790s; samplesPerSecond = 16206.6
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15522977 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0756s; samplesPerSecond = 16931.2
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12999825 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0742s; samplesPerSecond = 17261.6
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14637876 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0762s; samplesPerSecond = 16803.2
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14895916 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0762s; samplesPerSecond = 16806.9
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13170180 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0742s; samplesPerSecond = 17261.8
09/06/2016 12:19:12:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15748100 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0743s; samplesPerSecond = 17234.9
09/06/2016 12:19:12: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14803950 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.595538s
09/06/2016 12:19:12: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.44'

09/06/2016 12:19:12: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:12: Starting minibatch loop.
09/06/2016 12:19:12:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17797242 * 1280; EvalClassificationError = 0.09453125 * 1280; time = 0.0738s; samplesPerSecond = 17346.1
09/06/2016 12:19:12:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14360462 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0791s; samplesPerSecond = 16179.2
09/06/2016 12:19:12:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15861967 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0750s; samplesPerSecond = 17067.3
09/06/2016 12:19:12:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15259833 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0758s; samplesPerSecond = 16892.6
09/06/2016 12:19:13:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14746904 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0760s; samplesPerSecond = 16852.5
09/06/2016 12:19:13:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13469114 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0747s; samplesPerSecond = 17139.6
09/06/2016 12:19:13:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15044241 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0760s; samplesPerSecond = 16848.8
09/06/2016 12:19:13: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15045413 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.594291s
09/06/2016 12:19:13: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.45'

09/06/2016 12:19:13: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:13: Starting minibatch loop.
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12664578 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0782s; samplesPerSecond = 16376.5
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16433396 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0747s; samplesPerSecond = 17137.7
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14384487 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0778s; samplesPerSecond = 16452.7
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13878360 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0770s; samplesPerSecond = 16628.3
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14247766 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0738s; samplesPerSecond = 17346.1
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14789748 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0782s; samplesPerSecond = 16367.7
09/06/2016 12:19:13:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15105629 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0786s; samplesPerSecond = 16292.4
09/06/2016 12:19:13: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14529523 * 10000; EvalClassificationError = 0.07120000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.606599s
09/06/2016 12:19:13: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.46'

09/06/2016 12:19:13: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:13: Starting minibatch loop.
09/06/2016 12:19:13:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14702545 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0772s; samplesPerSecond = 16584.2
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15382305 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0768s; samplesPerSecond = 16656.3
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15464938 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0754s; samplesPerSecond = 16977.9
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11875648 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0752s; samplesPerSecond = 17024.7
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13451338 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0792s; samplesPerSecond = 16161.0
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15133672 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0746s; samplesPerSecond = 17148.3
09/06/2016 12:19:14:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13606710 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0729s; samplesPerSecond = 17548.7
09/06/2016 12:19:14: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14232028 * 10000; EvalClassificationError = 0.07670000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.595925s
09/06/2016 12:19:14: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.47'

09/06/2016 12:19:14: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:14: Starting minibatch loop.
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14784678 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0757s; samplesPerSecond = 16918.0
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14768790 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0788s; samplesPerSecond = 16246.5
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14861681 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0741s; samplesPerSecond = 17278.2
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14009428 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0754s; samplesPerSecond = 16965.1
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14016819 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0798s; samplesPerSecond = 16033.5
09/06/2016 12:19:14:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14270601 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0753s; samplesPerSecond = 17007.9
09/06/2016 12:19:15:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12744064 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0764s; samplesPerSecond = 16751.3
09/06/2016 12:19:15: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14264347 * 10000; EvalClassificationError = 0.07220000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.604878s
09/06/2016 12:19:15: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.48'

09/06/2016 12:19:15: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:15: Starting minibatch loop.
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15696771 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0757s; samplesPerSecond = 16907.7
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12931612 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0780s; samplesPerSecond = 16408.8
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14567537 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0780s; samplesPerSecond = 16413.2
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14286919 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0763s; samplesPerSecond = 16766.2
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14048314 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0780s; samplesPerSecond = 16403.9
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13541222 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0782s; samplesPerSecond = 16372.1
09/06/2016 12:19:15:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16446333 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0755s; samplesPerSecond = 16946.5
09/06/2016 12:19:15: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14473505 * 10000; EvalClassificationError = 0.07090000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.605127s
09/06/2016 12:19:15: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.49'

09/06/2016 12:19:15: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:15: Starting minibatch loop.
09/06/2016 12:19:15:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14710394 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0755s; samplesPerSecond = 16946.2
09/06/2016 12:19:15:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13555976 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0787s; samplesPerSecond = 16256.9
09/06/2016 12:19:15:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13793595 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0774s; samplesPerSecond = 16546.7
09/06/2016 12:19:16:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14865527 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0777s; samplesPerSecond = 16482.7
09/06/2016 12:19:16:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13444147 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0789s; samplesPerSecond = 16228.0
09/06/2016 12:19:16:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14464717 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0799s; samplesPerSecond = 16028.0
09/06/2016 12:19:16:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14754314 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0752s; samplesPerSecond = 17010.6
09/06/2016 12:19:16: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14187719 * 10000; EvalClassificationError = 0.07390000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.612766s
09/06/2016 12:19:16: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn'
09/06/2016 12:19:16: CNTKCommandTrainEnd: Simple_Demo

09/06/2016 12:19:16: Action "train" complete.


09/06/2016 12:19:16: ##############################################################################
09/06/2016 12:19:16: #                                                                            #
09/06/2016 12:19:16: # Action "write"                                                             #
09/06/2016 12:19:16: #                                                                            #
09/06/2016 12:19:16: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

09/06/2016 12:19:16: Action "write" complete.

09/06/2016 12:19:16: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/repo/cntk_github/CNTK/x64/release/cntk.exe configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Sep  6 2016 12:59:12
		Last modified date: Tue Sep  6 12:47:32 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\local\cudnn-7.5-windows10-x64-v5.1\cuda
		Build Branch: eldak/deterministicCPU2
		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
09/06/2016 12:19:16: -------------------------------------------------------------------
09/06/2016 12:19:16: Build info: 

09/06/2016 12:19:16: 		Built time: Sep  6 2016 12:59:12
09/06/2016 12:19:16: 		Last modified date: Tue Sep  6 12:47:32 2016
09/06/2016 12:19:16: 		Build type: Release
09/06/2016 12:19:16: 		Build target: GPU
09/06/2016 12:19:16: 		With 1bit-SGD: yes
09/06/2016 12:19:16: 		Math lib: mkl
09/06/2016 12:19:16: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
09/06/2016 12:19:16: 		CUB_PATH: c:\Tools\cub-1.4.1\
09/06/2016 12:19:16: 		CUDNN_PATH: c:\local\cudnn-7.5-windows10-x64-v5.1\cuda
09/06/2016 12:19:16: 		Build Branch: eldak/deterministicCPU2
09/06/2016 12:19:16: 		Build SHA1: ab9a0ca3d973da87afb2dc4b0599e42fb45b0686
09/06/2016 12:19:16: 		Built by eldak on ELDAK-0
09/06/2016 12:19:16: 		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
09/06/2016 12:19:16: -------------------------------------------------------------------
09/06/2016 12:19:17: -------------------------------------------------------------------
09/06/2016 12:19:17: GPU info:

09/06/2016 12:19:17: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2048 MB
09/06/2016 12:19:17: 		Device[1]: cores = 576; computeCapability = 5.0; type = "Quadro K620"; memory = 2048 MB
09/06/2016 12:19:17: -------------------------------------------------------------------

09/06/2016 12:19:17: Running on ELDAK-0 at 2016/09/06 12:19:17
09/06/2016 12:19:17: Command line: 
C:\repo\cntk_github\CNTK\x64\release\cntk.exe  configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu  DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple  OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true


Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
09/06/2016 12:19:17: Commands: Simple_Demo Simple_Demo_Output
09/06/2016 12:19:17: Precision = "float"
09/06/2016 12:19:17: forceDeterministcAlgorithms flag is specified. Using 1 CPU thread.
09/06/2016 12:19:17: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn
09/06/2016 12:19:17: CNTKCommandTrainInfo: Simple_Demo : 50
09/06/2016 12:19:17: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

09/06/2016 12:19:17: ##############################################################################
09/06/2016 12:19:17: #                                                                            #
09/06/2016 12:19:17: # Action "train"                                                             #
09/06/2016 12:19:17: #                                                                            #
09/06/2016 12:19:17: ##############################################################################

09/06/2016 12:19:17: CNTKCommandTrainBegin: Simple_Demo

09/06/2016 12:19:17: Starting from checkpoint. Loading network from 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn.49'.
SimpleNetworkBuilder Using CPU

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

09/06/2016 12:19:17: Loaded model with 25 nodes on CPU.

09/06/2016 12:19:17: Training criterion node(s):
09/06/2016 12:19:17: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

09/06/2016 12:19:17: Evaluation criterion node(s):
09/06/2016 12:19:17: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }


09/06/2016 12:19:17: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

09/06/2016 12:19:17: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:19:17: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
09/06/2016 12:19:17: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
09/06/2016 12:19:17: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
09/06/2016 12:19:17: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
09/06/2016 12:19:17: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

09/06/2016 12:19:17: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

09/06/2016 12:19:17: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

09/06/2016 12:19:17: Starting minibatch loop.
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14710395 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0375s; samplesPerSecond = 34131.5
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13555977 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0100s; samplesPerSecond = 128295.1
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13793597 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0100s; samplesPerSecond = 128076.8
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14865532 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0087s; samplesPerSecond = 146352.6
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13444152 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0080s; samplesPerSecond = 160945.6
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14464722 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0082s; samplesPerSecond = 156307.2
09/06/2016 12:19:17:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14754314 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0081s; samplesPerSecond = 158848.3
09/06/2016 12:19:17: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14187721 * 10000; EvalClassificationError = 0.07390000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.09998s
09/06/2016 12:19:17: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/models/simple.dnn'
09/06/2016 12:19:17: CNTKCommandTrainEnd: Simple_Demo

09/06/2016 12:19:17: Action "train" complete.


09/06/2016 12:19:17: ##############################################################################
09/06/2016 12:19:17: #                                                                            #
09/06/2016 12:19:17: # Action "write"                                                             #
09/06/2016 12:19:17: #                                                                            #
09/06/2016 12:19:17: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to F:\cygwin64\tmp\cntk-test-20160906131846.86708\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

09/06/2016 12:19:17: Action "write" complete.

09/06/2016 12:19:17: __COMPLETED__